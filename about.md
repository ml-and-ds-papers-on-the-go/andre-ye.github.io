[Home](https://andre-ye.github.io/) > About

## About ğŸ¤™

**Hey ğŸ‘‹ - I'm Andre.** I'm passionate about machine learning and better understanding the "black box" that is the neural network. By better understanding implicit biases and the thinking processes of deep learning models, I believe we will better be able to use it in our society.

ğŸ“‘ My resume is [here](https://andre-ye.github.io/scripts/andre-ye-resume.pdf){:target="_blank"}.

ğŸ”— Connect with me on LinkedIn [here](https://linkedin.com/in/andre-ye){:target="_blank"}.

ğŸ–¨ï¸ Some of my favorite papers:
- [The Lottery Ticket Hypothesis: Finding Sparse, Trainable Neural Networks](https://arxiv.org/abs/1803.03635v1){:target="_blank"}.
- [Whatâ€™s Hidden in a Randomly Weighted Neural Network?](https://arxiv.org/pdf/1911.13299.pdf){:target="_blank"}.
- [Scaling description of generalization with number of parameters in deep learning](https://arxiv.org/pdf/1901.01608.pdf){:target="_blank"}.
- [Reconciling modern machine learning practice and the bias-variance trade-off](https://arxiv.org/pdf/1812.11118.pdf){:target="_blank"}.
- [Understanding deep learning requires rethinking generalization](https://arxiv.org/abs/1611.03530){:target="_blank"}.

In the mean-time, I like to swim ğŸŠâ€, read ğŸ“š, and play piano ğŸ¹.

<br>

---

<br>

### Data Science Articles & Writing ğŸ“° ğŸ“ˆ
I write articles about machine learning, data science, and occasionally mathematics [here](https://andre-ye.medium.com/){:target="_blank"}. Some of my favorite articles:
- [The Beauty of Bayesian Optimization, Explained in Simple Terms](https://towardsdatascience.com/the-beauty-of-bayesian-optimization-explained-in-simple-terms-81f3ee13b10f){:target="_blank"}
- [Obtaining Top Neural Network Performance Without Any Training](https://medium.com/analytics-vidhya/obtaining-top-neural-network-performance-without-any-training-5af0af464c59){:target="_blank"}
- [If You're Hyped About GPT-3 Writing Code, You Havenâ€™t Heard of NAS](https://towardsdatascience.com/if-youre-hyped-about-gpt-3-writing-code-you-haven-t-heard-of-nas-19c8c30fcc8a){:target="_blank"}
- [The Clever Trick Behind Googleâ€™s InceptionNet: The 1Ã—1 Convolution?](https://towardsdatascience.com/the-clever-trick-behind-googles-inception-the-1-1-convolution-58815b20113){:target="_blank"}
- [Long Short-Term Memory Networks Are Dying: Whatâ€™s Replacing It?](https://towardsdatascience.com/long-short-term-memory-networks-are-dying-whats-replacing-it-5ff3a99399fe){:target="_blank"}
- [Finally, an intuitive explanation of why ReLU works](https://towardsdatascience.com/if-rectified-linear-units-are-linear-how-do-they-add-nonlinearity-40247d3e4792){:target="_blank"}
- [The Fascinating No-Gradient Approach to Neural Net Optimization](https://towardsdatascience.com/the-fascinating-no-gradient-approach-to-neural-net-optimization-abb287f88c97){:target="_blank"}

I've also guest-written on other platforms, including [KDnuggets](https://www.kdnuggets.com/2021/01/ultimate-scikit-learn-machine-learning-cheatsheet.html){:target="_blank"}, [Netpune.ai](https://neptune.ai/blog/author/andre-ye){:target="_blank"}, and [Experfy](https://www.experfy.com/blog/author/andre-ye/){:target="_blank"}, among other platforms.


<a href="https://www.kdnuggets.com/2020/12/top-stories-2020-nov.html"><img src="https://www.kdnuggets.com/images/tkb-2011-s.png" width=96 alt="Silver Blog" align="right"></a><a href="https://www.kdnuggets.com/2021/02/top-news-week-0125-0131.html"><img src="https://www.kdnuggets.com/images/tkb-2101-g.png" width=96 alt="Gold Blog" align="right"></a>
Two of my articles on KDnuggets, an organization that awards the "Nobel Prize of Data Science" - the SIGKDD award - with 700+ visitors, recieved silver and gold badges for being top-viewed and top-shared on the platform.

*Fun fact:* One of my articles was cited as a reference for a [Wikipedia page](https://en.wikipedia.org/wiki/LightGBM){:target="_blank"} on the LGM gradient boosting framework.

*Fun fact:* A few of my articles have been translated into other languages, like [this one](https://www.infoq.cn/article/qUhqVdHxC0uxPFyDbt7h){:target="_blank"} on adversarial attacks using input perbutations to convolutional neural networks.

*Fun fact:* The University of Delaware Masters in Data Science Program [listed](https://www.msds.udel.edu/resources/data-resources/){:target="_blank"} an article I wrote on built-in datasets in APIs as a data resource.

<br>

---

<br>

### Projects

âŒ¨ï¸ Check out [Critiq](https://critiq.tech){:target="_blank"}, a site [Carter Chan-Nui](https://www.linkedin.com/in/carterchannui/){:target="_blank"}, [Om Shah](https://www.linkedin.com/in/om-shah-5a0b571ab/){:target="_blank"}, and I coded to reimagine what peer revision for essays can be and do.



<br>

---

<br>

[This page is still a work in progress.]
